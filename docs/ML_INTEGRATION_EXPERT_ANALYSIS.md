# ü§ñ ML Integration - Expert Analysis & MVP Strategy

**Date**: January 2025  
**Context**: QueueMed - Moroccan Healthcare Queue Management  
**Goal**: Expert recommendations for ML wait time prediction MVP

---

## üéØ Executive Summary

**Recommendation**: **Phased Approach with Smart Fallbacks**

1. **MVP Phase** (Weeks 1-4): Rule-based estimator with ML-ready architecture
2. **ML Phase 1** (Weeks 5-8): Simple ML model (Linear Regression/Random Forest)
3. **ML Phase 2** (Weeks 9-12): Advanced ML with retraining pipeline
4. **Production** (Ongoing): Continuous improvement with A/B testing

**Key Principle**: **Never break the user experience** - Always have a fallback.

---

## üìä Current State Analysis

### ‚úÖ **What You Have (Strengths)**
1. ‚úÖ **Solid Data Collection**: Actual wait times, queue snapshots, feature infrastructure
2. ‚úÖ **Clean Architecture**: Service layer, repository pattern, proper separation
3. ‚úÖ **ML-Ready Infrastructure**: Edge Function proxy, MlApiClient, data pipeline
4. ‚úÖ **50+ Features Identified**: Comprehensive feature engineering plan
5. ‚úÖ **PostgreSQL Database**: Rich relational data, JSONB for flexibility

### ‚ö†Ô∏è **What's Missing (Gaps)**
1. ‚ö†Ô∏è **No ML Model Yet**: Need to build/deploy
2. ‚ö†Ô∏è **Limited Training Data**: Need sufficient historical data per clinic
3. ‚ö†Ô∏è **No Fallback Strategy**: What if ML service is down?
4. ‚ö†Ô∏è **No Model Versioning**: Need to track model performance
5. ‚ö†Ô∏è **No A/B Testing**: Can't compare models safely

---

## üèÜ Best Practices for Healthcare ML (Industry Standards)

### **1. Safety First - Always Have Fallbacks**
**Why**: Healthcare apps can't fail silently. Patients rely on wait time predictions.

**Implementation**:
```typescript
// Three-tier fallback strategy
1. ML Model (if available & confident)
2. Rule-based estimator (if ML fails)
3. Historical average (if all else fails)
```

**Example**:
- ML predicts 15 min (confidence: 0.85) ‚Üí Use ML ‚úÖ
- ML predicts 15 min (confidence: 0.45) ‚Üí Use rule-based ‚ö†Ô∏è
- ML service down ‚Üí Use historical average ‚úÖ

### **2. Explainability & Transparency**
**Why**: Healthcare providers need to trust predictions. "Why 15 minutes?"

**Implementation**:
- Return top 3 contributing features
- Show confidence intervals
- Explain when using fallback

**Example Response**:
```json
{
  "waitTimeMinutes": 15,
  "confidence": 0.85,
  "mode": "ml",
  "explanation": {
    "topFactors": [
      "Queue position: 2 (high impact)",
      "Current delay: 5 minutes (medium impact)",
      "Staff utilization: 0.75 (medium impact)"
    ],
    "confidenceInterval": [10, 20]
  }
}
```

### **3. Data Quality Over Model Complexity**
**Why**: A simple model with good data beats a complex model with bad data.

**MVP Approach**:
- Start with **Linear Regression** or **Random Forest** (simple, interpretable)
- Focus on **data quality** (clean features, handle missing values)
- Add complexity later (XGBoost, Neural Networks) only if needed

### **4. Clinic-Specific Models**
**Why**: Each clinic has different patterns (size, specialty, patient flow).

**Implementation**:
- Train separate models per clinic (if enough data)
- Or use clinic features in a single model (if limited data)
- Start with single model, split later

### **5. Continuous Monitoring & Retraining**
**Why**: Healthcare patterns change (seasons, staff changes, new procedures).

**Implementation**:
- Monitor prediction accuracy weekly
- Retrain monthly (or when accuracy drops)
- A/B test new models before full rollout

---

## üéØ MVP Strategy: Phased Approach

### **Phase 1: MVP with Rule-Based Estimator** (Weeks 1-4)
**Goal**: Ship working wait time predictions without ML complexity

**Approach**:
1. **Build rule-based estimator** (simple, reliable)
2. **Use existing ML infrastructure** (Edge Function, MlApiClient)
3. **Collect training data** (actual wait times)
4. **Validate data quality** (ensure enough data per clinic)

**Rule-Based Algorithm**:
```python
def estimate_wait_time(appointment):
    # Simple rule-based logic
    base_wait = 10  # Base wait time
    
    # Queue position impact
    position_factor = appointment.queue_position * 5
    
    # Current delay impact
    delay_factor = appointment.current_delay_minutes or 0
    
    # Staff utilization impact
    utilization = appointment.staff_utilization or 0.5
    utilization_factor = utilization * 20
    
    # Historical average (if available)
    historical_avg = appointment.historical_avg_wait_time or 15
    
    # Weighted combination
    estimated = (
        0.3 * base_wait +
        0.3 * position_factor +
        0.2 * delay_factor +
        0.1 * utilization_factor +
        0.1 * historical_avg
    )
    
    return max(5, min(estimated, 120))  # Clamp between 5-120 minutes
```

**Benefits**:
- ‚úÖ Works immediately (no training data needed)
- ‚úÖ Interpretable (easy to explain)
- ‚úÖ Reliable (no ML model failures)
- ‚úÖ Fast (no model inference)

**Limitations**:
- ‚ö†Ô∏è Less accurate than ML (but acceptable for MVP)
- ‚ö†Ô∏è Doesn't learn from patterns

**When to Use**:
- MVP launch
- ML service down
- Low confidence predictions
- New clinics (no training data)

---

### **Phase 2: Simple ML Model** (Weeks 5-8)
**Goal**: Add ML model when you have sufficient training data

**Approach**:
1. **Collect 1000+ completed appointments** per clinic
2. **Train simple model** (Linear Regression or Random Forest)
3. **A/B test** against rule-based estimator
4. **Gradual rollout** (10% ‚Üí 50% ‚Üí 100%)

**Model Choice**: **Random Forest**
- ‚úÖ Handles non-linear relationships
- ‚úÖ Feature importance (explainability)
- ‚úÖ Robust to outliers
- ‚úÖ Fast inference
- ‚úÖ Works well with 50+ features

**Training Data Requirements**:
- **Minimum**: 500 completed appointments per clinic
- **Recommended**: 2000+ for robust model
- **Features**: Start with top 20-30 high-priority features

**Deployment**:
```python
# FastAPI endpoint
@app.post("/predict")
async def predict_wait_time(request: PredictionRequest):
    # 1. Fetch appointment data
    appointment = fetch_appointment(request.appointmentId)
    
    # 2. Extract features
    features = extract_features(appointment)
    
    # 3. Predict (with fallback)
    if model_available and confidence_high:
        prediction = ml_model.predict(features)
    else:
        prediction = rule_based_estimator.estimate(appointment)
    
    # 4. Return with explanation
    return {
        "waitTimeMinutes": prediction,
        "confidence": calculate_confidence(features),
        "mode": "ml" if model_used else "rule-based",
        "explanation": get_explanation(features)
    }
```

---

### **Phase 3: Advanced ML** (Weeks 9-12)
**Goal**: Improve accuracy with advanced models and retraining

**Approach**:
1. **Try advanced models** (XGBoost, LightGBM)
2. **Feature engineering** (interactions, polynomial features)
3. **Automated retraining** (weekly/monthly)
4. **Model versioning** (track performance)

**When to Upgrade**:
- ‚úÖ Have 5000+ training examples
- ‚úÖ Rule-based accuracy < 70%
- ‚úÖ ML model shows clear improvement
- ‚úÖ Infrastructure ready for retraining

---

## üí∞ Cost & Complexity Analysis

### **Option 1: Rule-Based Only (MVP)**
**Cost**: $0/month (runs in Edge Function)  
**Complexity**: Low  
**Accuracy**: ~60-70%  
**Time to Ship**: 1-2 weeks  
**Best For**: MVP, new clinics, fallback

### **Option 2: Simple ML (Python/FastAPI on Railway/Render)**
**Cost**: $5-20/month (serverless or small instance)  
**Complexity**: Medium  
**Accuracy**: ~75-85%  
**Time to Ship**: 4-6 weeks  
**Best For**: Production MVP, established clinics

### **Option 3: Advanced ML (MLOps Platform)**
**Cost**: $50-200/month (MLflow, Weights & Biases, or cloud ML)  
**Complexity**: High  
**Accuracy**: ~80-90%  
**Time to Ship**: 8-12 weeks  
**Best For**: Scale, multiple clinics, advanced features

### **Option 4: Cloud ML Service (AWS SageMaker, GCP AI Platform)**
**Cost**: $100-500/month (pay per prediction)  
**Complexity**: Medium-High  
**Accuracy**: ~80-90%  
**Time to Ship**: 6-8 weeks  
**Best For**: Enterprise, high volume

**Recommendation**: **Start with Option 1 (Rule-Based) ‚Üí Move to Option 2 (Simple ML) when ready**

---

## üèóÔ∏è Architecture Recommendations

### **MVP Architecture (Recommended)**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Frontend (React)                                        ‚îÇ
‚îÇ  - Calls MlApiClient.predictWaitTime(appointmentId)      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Edge Function (Supabase)                               ‚îÇ
‚îÇ  - Thin proxy to ML service                            ‚îÇ
‚îÇ  - Handles authentication                              ‚îÇ
‚îÇ  - Returns prediction or error                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ ML Service (Python/FastAPI)                            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ 1. Fetch appointment data (Supabase)            ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ 2. Extract features                             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ 3. Predict (ML or rule-based)                   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ 4. Return prediction + explanation               ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Database (Supabase PostgreSQL)                         ‚îÇ
‚îÇ  - Appointments, queue snapshots, historical data     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### **Deployment Options**

#### **Option A: Serverless (Recommended for MVP)**
- **Platform**: Railway, Render, Fly.io
- **Cost**: $5-20/month
- **Pros**: Auto-scaling, easy deployment, low maintenance
- **Cons**: Cold starts (100-500ms), limited customization

#### **Option B: Container (Docker)**
- **Platform**: Railway, Render, DigitalOcean
- **Cost**: $10-30/month
- **Pros**: Full control, no cold starts, predictable performance
- **Cons**: More setup, need to manage scaling

#### **Option C: Cloud ML Platform**
- **Platform**: AWS SageMaker, GCP AI Platform, Azure ML
- **Cost**: $50-200/month
- **Pros**: Built-in MLOps, model versioning, monitoring
- **Cons**: Vendor lock-in, higher cost, more complex

**Recommendation**: **Start with Option A (Serverless) ‚Üí Move to Option B if needed**

---

## üìà Data Requirements & Validation

### **Minimum Viable Data**
- **Per Clinic**: 500 completed appointments
- **Features**: Top 20 high-priority features
- **Time Period**: Last 3 months (captures seasonality)

### **Data Quality Checks**
1. **Completeness**: < 10% missing values per feature
2. **Outliers**: Flag wait times > 4 hours or < 0 minutes
3. **Consistency**: Validate timing relationships (start > check-in)
4. **Freshness**: Queue snapshots < 15 minutes old

### **When to Train Model**
- ‚úÖ Have 500+ completed appointments per clinic
- ‚úÖ Data quality checks pass
- ‚úÖ Features are stable (no schema changes)
- ‚úÖ Have validation set (20% of data)

---

## üéØ MVP Implementation Plan

### **Week 1-2: Rule-Based Estimator**
1. ‚úÖ Build rule-based estimator in Python
2. ‚úÖ Deploy as FastAPI service
3. ‚úÖ Connect Edge Function to ML service
4. ‚úÖ Test end-to-end flow
5. ‚úÖ Add fallback logic

### **Week 3-4: Data Collection & Validation**
1. ‚úÖ Ensure data collection is working
2. ‚úÖ Validate data quality
3. ‚úÖ Export training data
4. ‚úÖ Analyze feature distributions
5. ‚úÖ Identify data gaps

### **Week 5-6: Simple ML Model (If Data Ready)**
1. ‚úÖ Train Random Forest model
2. ‚úÖ Evaluate on validation set
3. ‚úÖ Compare with rule-based
4. ‚úÖ Deploy with A/B testing
5. ‚úÖ Monitor performance

### **Week 7-8: Production Hardening**
1. ‚úÖ Add monitoring & alerts
2. ‚úÖ Implement retraining pipeline
3. ‚úÖ Add model versioning
4. ‚úÖ Document API
5. ‚úÖ Load testing

---

## üö® Risk Mitigation

### **Risk 1: ML Service Down**
**Mitigation**: Always have rule-based fallback
```python
try:
    prediction = ml_model.predict(features)
except Exception:
    prediction = rule_based_estimator.estimate(appointment)
```

### **Risk 2: Low Training Data**
**Mitigation**: Use rule-based until sufficient data
```python
if training_data_count < 500:
    return rule_based_estimator.estimate(appointment)
else:
    return ml_model.predict(features)
```

### **Risk 3: Poor Model Accuracy**
**Mitigation**: A/B test and gradual rollout
- Start with 10% of predictions
- Compare accuracy vs rule-based
- Increase gradually if better

### **Risk 4: Model Drift**
**Mitigation**: Monitor and retrain regularly
- Track prediction accuracy weekly
- Retrain monthly (or when accuracy drops)
- Alert on significant drift

---

## üá≤üá¶ Moroccan Context Considerations

### **1. Cultural Factors**
- **Ramadan**: Different patterns during Ramadan (shorter hours, different flow)
- **Holidays**: Moroccan holidays affect patient volume
- **Language**: Arabic/French support in explanations

### **2. Healthcare System**
- **Public vs Private**: Different patterns, different models
- **Insurance**: CNSS, RAMED affect patient flow
- **Walk-ins**: High walk-in rate (need good walk-in features)

### **3. Technology Constraints**
- **Internet**: Variable connectivity (need offline fallback)
- **Mobile-First**: Most users on mobile (optimize for mobile)
- **SMS**: Primary notification channel (integrate with predictions)

---

## ‚úÖ Final Recommendations

### **For MVP (Next 4 Weeks)**
1. ‚úÖ **Start with rule-based estimator** (works immediately)
2. ‚úÖ **Deploy ML service infrastructure** (Python/FastAPI on Railway)
3. ‚úÖ **Collect training data** (ensure data quality)
4. ‚úÖ **Add fallback logic** (never break user experience)
5. ‚úÖ **Monitor predictions** (track accuracy, identify issues)

### **For Production (Weeks 5-12)**
1. ‚úÖ **Train simple ML model** (Random Forest)
2. ‚úÖ **A/B test against rule-based** (validate improvement)
3. ‚úÖ **Gradual rollout** (10% ‚Üí 50% ‚Üí 100%)
4. ‚úÖ **Add retraining pipeline** (automated monthly)
5. ‚úÖ **Monitor and iterate** (continuous improvement)

### **Technology Stack (Recommended)**
- **ML Service**: Python 3.11 + FastAPI
- **ML Library**: scikit-learn (Random Forest)
- **Deployment**: Railway or Render (serverless)
- **Database**: Supabase PostgreSQL (existing)
- **Monitoring**: Logging + simple metrics (upgrade later)

---

## üéì Key Takeaways

1. **Start Simple**: Rule-based ‚Üí Simple ML ‚Üí Advanced ML
2. **Always Have Fallback**: Never break user experience
3. **Data Quality > Model Complexity**: Focus on clean data first
4. **Explainability Matters**: Healthcare needs trust
5. **Monitor Everything**: Track accuracy, drift, errors
6. **Iterate Gradually**: A/B test, gradual rollout
7. **Cost-Conscious**: Start cheap, scale when needed

---

## üìû Next Steps

1. **Review this analysis** with your team
2. **Decide on MVP approach** (rule-based vs simple ML)
3. **Choose deployment platform** (Railway, Render, etc.)
4. **Set up ML service** (Python/FastAPI)
5. **Implement rule-based estimator** (Week 1)
6. **Collect and validate data** (Week 2-3)
7. **Train ML model** (Week 4-5, if data ready)

**Ready to start? Let's build the rule-based estimator first!** üöÄ

