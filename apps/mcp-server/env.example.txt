# ===========================================
# QueueMed MCP Server Configuration
# Copy this file to .env and fill in your values
# ===========================================

# Environment
NODE_ENV=development
LOG_LEVEL=debug

# ===========================================
# Supabase Configuration (Required)
# ===========================================
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_SERVICE_KEY=eyJ...your-service-key-here

# ===========================================
# LLM Providers (Phase 3)
# ===========================================
# Default provider: ollama | groq | openai | anthropic
LLM_DEFAULT_PROVIDER=groq

# Groq (Fast cloud inference - Recommended for start)
GROQ_API_KEY=gsk_your_key_here
GROQ_MODEL=llama-3.3-70b-versatile

# Ollama (On-prem for data residency)
OLLAMA_ENABLED=false
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=llama3.1:8b

# OpenAI (Optional)
OPENAI_API_KEY=sk-your-key-here
OPENAI_MODEL=gpt-4o-mini

# Anthropic (Optional - Safety-focused)
ANTHROPIC_API_KEY=sk-ant-your-key-here
ANTHROPIC_MODEL=claude-3-5-sonnet-20241022

# ===========================================
# Web Search (Phase 3)
# ===========================================
TAVILY_API_KEY=tvly-your-key-here

# ===========================================
# Server Configuration
# ===========================================
SERVER_PORT=3001

